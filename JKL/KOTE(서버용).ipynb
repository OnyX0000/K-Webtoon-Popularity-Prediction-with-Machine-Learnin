{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 6.74M/6.74M [00:00<00:00, 11.0MB/s]\n",
      "Downloading data: 100%|██████████| 843k/843k [00:00<00:00, 11.8MB/s]\n",
      "Downloading data: 100%|██████████| 858k/858k [00:00<00:00, 11.1MB/s]\n",
      "Generating train split: 40000 examples [00:00, 115071.17 examples/s]\n",
      "Generating test split: 5000 examples [00:00, 115001.29 examples/s]\n",
      "Generating validation split: 5000 examples [00:00, 115012.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 40000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"searle-j/kote\", trust_remote_code=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39087</td>\n",
       "      <td>내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.</td>\n",
       "      <td>[2, 13, 15, 16, 29, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30893</td>\n",
       "      <td>정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...</td>\n",
       "      <td>[0, 5, 7, 10, 19, 22, 29, 35, 36, 38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45278</td>\n",
       "      <td>새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...</td>\n",
       "      <td>[1, 2, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16398</td>\n",
       "      <td>미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>[9, 15, 20, 23, 26, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13653</td>\n",
       "      <td>네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ</td>\n",
       "      <td>[1, 2, 8, 9, 11, 13, 15, 16, 28, 29, 32, 40, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>11284</td>\n",
       "      <td>멋지게 잘나왔네요! 고생하신보람이있겠습니다.</td>\n",
       "      <td>[1, 2, 4, 7, 8, 13, 15, 16, 28, 29, 32, 39, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>44732</td>\n",
       "      <td>고막주의라 그래 잔뜩 긴장햇는데 에이든은 우는것도 귀엽네영</td>\n",
       "      <td>[15, 16, 32, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>38158</td>\n",
       "      <td>박정호 교수님은 sbs 블루베리부터 왕팬입니다.</td>\n",
       "      <td>[1, 7, 8, 13, 16, 24, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>860</td>\n",
       "      <td>겁나 어메이징한 영화! 에이미란 이름엔 저주가 얹은듯</td>\n",
       "      <td>[2, 9, 10, 15, 18, 23, 33, 35, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15795</td>\n",
       "      <td>인도네시아 우리는 당신을 믿습니다ㅋㅋㅋㅋㅋㅋㅌㅋ하이퍼리얼리즘이네...</td>\n",
       "      <td>[9, 15, 20, 23, 28]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               text  \\\n",
       "0      39087              내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.   \n",
       "1      30893  정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...   \n",
       "2      45278  새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...   \n",
       "3      16398       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
       "4      13653                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
       "...      ...                                                ...   \n",
       "39995  11284                           멋지게 잘나왔네요! 고생하신보람이있겠습니다.   \n",
       "39996  44732                   고막주의라 그래 잔뜩 긴장햇는데 에이든은 우는것도 귀엽네영   \n",
       "39997  38158                         박정호 교수님은 sbs 블루베리부터 왕팬입니다.   \n",
       "39998    860                      겁나 어메이징한 영화! 에이미란 이름엔 저주가 얹은듯   \n",
       "39999  15795             인도네시아 우리는 당신을 믿습니다ㅋㅋㅋㅋㅋㅋㅌㅋ하이퍼리얼리즘이네...   \n",
       "\n",
       "                                                  labels  \n",
       "0                                [2, 13, 15, 16, 29, 39]  \n",
       "1                  [0, 5, 7, 10, 19, 22, 29, 35, 36, 38]  \n",
       "2                                              [1, 2, 7]  \n",
       "3                            [9, 15, 20, 23, 26, 28, 29]  \n",
       "4       [1, 2, 8, 9, 11, 13, 15, 16, 28, 29, 32, 40, 42]  \n",
       "...                                                  ...  \n",
       "39995  [1, 2, 4, 7, 8, 13, 15, 16, 28, 29, 32, 39, 40...  \n",
       "39996                                   [15, 16, 32, 41]  \n",
       "39997                          [1, 7, 8, 13, 16, 24, 42]  \n",
       "39998                 [2, 9, 10, 15, 18, 23, 33, 35, 39]  \n",
       "39999                                [9, 15, 20, 23, 28]  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(ds['train'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Device count: 2\n",
      "Current GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "# PyTorch에서 GPU 설정 확인\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hugging Face에서 토크나이저와 모델 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"searle-j/kote_for_easygoing_people\", trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"searle-j/kote_for_easygoing_people\")\n",
    "\n",
    "# 감정 분석 모델 설정 \n",
    "pipe = TextClassificationPipeline(\n",
    "    model=model.to(device),  # 모델을 GPU로 이동\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if device == \"cuda\" else -1,  # GPU(0) 또는 CPU(-1)\n",
    "    return_all_scores=True,\n",
    "    function_to_apply='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish = pd.read_csv('best_comments_with_episodes.csv')\n",
    "webtoon = pd.read_csv('webtoon_best_comments_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(text_list):\n",
    "    \"\"\"\n",
    "    감정 분석을 수행하여 각 텍스트에 대한 가장 높은 점수의 레이블을 반환합니다.\n",
    "\n",
    "    Parameters:\n",
    "        text_list (list): 텍스트 데이터 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 각 텍스트에 대한 감정 분석 결과 레이블\n",
    "    \"\"\"\n",
    "    emotions = []\n",
    "    for text in tqdm(text_list, desc=\"Performing Sentiment Analysis\", unit=\"comment\"):\n",
    "        pipe_text = pipe([text])  # pipe는 개별적으로 호출\n",
    "        highest_label = max(pipe_text[0], key=lambda x: x[\"score\"])[\"label\"]\n",
    "        emotions.append(highest_label)\n",
    "    return emotions\n",
    "\n",
    "\n",
    "def save_with_emotions(df, text_column, output_file):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 댓글 열을 분석하고 감정 결과를 추가한 후 저장합니다.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): 감정 분석을 수행할 데이터프레임\n",
    "        text_column (str): 댓글이 있는 열 이름\n",
    "        output_file (str): 저장할 파일 이름\n",
    "    \"\"\"\n",
    "    text_list = df[text_column].tolist()\n",
    "    print(f\"Processing {output_file}...\")\n",
    "    \n",
    "    # 감정 분석 수행\n",
    "    df[\"emotion\"] = perform_sentiment_analysis(text_list)\n",
    "    \n",
    "    # 결과 저장\n",
    "    df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"{output_file} 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing webtoon_emotion.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Sentiment Analysis:   0%|          | 3/37574 [00:00<21:20, 29.34comment/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Performing Sentiment Analysis: 100%|██████████| 37574/37574 [01:23<00:00, 450.98comment/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtoon_emotion.csv 저장 완료!\n",
      "Processing finish_emotion.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Sentiment Analysis: 100%|██████████| 46549/46549 [01:42<00:00, 452.67comment/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_emotion.csv 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 연재중 웹툰 댓글 감정 분석\n",
    "save_with_emotions(webtoon, text_column=\"Comment\", output_file=\"webtoon_emotion.csv\")\n",
    "\n",
    "# 완결결 웹툰 댓글 감정 분석\n",
    "save_with_emotions(finish, text_column=\"Comment\", output_file=\"finish_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2_team1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
